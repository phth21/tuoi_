import threading
import paho.mqtt.client as mqtt
import requests, time, json, re, os
from datetime import datetime, timedelta
from flask import Flask, render_template, request, jsonify, session, redirect, url_for
from pymongo import MongoClient
import google.generativeai as genai

# ====================== C·∫§U H√åNH SERVER ======================
app = Flask(__name__)
app.secret_key = 'thao_cute_sieu_cap_vipro' 

# T√ÄI KHO·∫¢N
USERS = {
    'admin': {'pass': 'admin123', 'role': 'ADMIN'},  
    'khach': {'pass': '1111',       'role': 'VIEWER'} 
}

# CONFIG BACKEND
GEMINI_API_KEY = os.getenv("GEMINI_KEY")
if not GEMINI_API_KEY:
    if not GEMINI_API_KEY:
        raise RuntimeError("‚ùå GEMINI_KEY environment variable not set")

OPENWEATHER_KEY = os.getenv("OWM_KEY", "5803b3e6056e6886cfa874414788f232")
MONGO_URI = os.getenv("MONGO_URI")

# MONGODB CONNECT
db_collection = None
try:
    if MONGO_URI:
        mongo_client = MongoClient(MONGO_URI)
        db = mongo_client.get_database("smart_garden_db")
        db_collection = db.history
        print("--- MONGODB ATLAS CONNECTED ---")
    else:
        print("‚ö†Ô∏è C·∫£nh b√°o: Ch∆∞a c√≥ MONGO_URI, l·ªãch s·ª≠ s·∫Ω kh√¥ng ƒë∆∞·ª£c l∆∞u.")
except Exception as e: print(f"‚ùå L·ªói MongoDB: {e}")

# ====================== AI AUTO-DISCOVERY (TH·ª¨ SAI TR·ª∞C TI·∫æP) ======================
genai.configure(api_key=GEMINI_API_KEY)
model = None

def init_gemini_model():
    """
    H√†m kh·ªüi t·∫°o AI theo ki·ªÉu 'Th·ª≠ Sai'. 
    N√≥ s·∫Ω g·ª≠i th·ª≠ 1 tin nh·∫Øn 'test' t·ªõi Google. 
    C√°i n√†o kh√¥ng l·ªói 404 th√¨ l·∫•y c√°i ƒë√≥.
    """
    global model
    print("\nüîç ƒêang d√≤ t√¨m model AI ph√π h·ª£p...")
    
    # Danh s√°ch c√°c t√™n model c√≥ th·ªÉ d√πng (∆Øu ti√™n Flash -> Pro -> C≈©)
    candidates = [
        "gemini-1.5-flash",          # B·∫£n chu·∫©n, nhanh, free
        "gemini-1.5-flash-latest",   # B·∫£n m·ªõi nh·∫•t c·ªßa Flash
        "gemini-1.5-pro",            # B·∫£n Pro (th√¥ng minh h∆°n)
        "gemini-1.5-pro-latest",     # B·∫£n Pro m·ªõi nh·∫•t
        "gemini-1.0-pro",            # B·∫£n ·ªïn ƒë·ªãnh ƒë·ªùi c≈©
    ]
    
    for name in candidates:
        try:
            print(f"   üëâ ƒêang th·ª≠: {name}...", end=" ")
            temp_model = genai.GenerativeModel(name)
            
            # QUAN TR·ªåNG: G·ªçi th·ª≠ 1 l·ªánh gi·∫£ ƒë·ªÉ xem c√≥ b·ªã l·ªói 404 kh√¥ng
            temp_model.generate_content("Test") 
            
            print("‚úÖ K·∫æT N·ªêI TH√ÄNH C√îNG!")
            return temp_model
        except Exception as e:
            # N·∫øu l·ªói, in ra ng·∫Øn g·ªçn r·ªìi th·ª≠ c√°i ti·∫øp theo
            err_msg = str(e)
            if "404" in err_msg or "not found" in err_msg:
                print("‚ùå (Kh√¥ng t√¨m th·∫•y/L·ªói model)")
            else:
                print(f"‚ùå (L·ªói kh√°c: {err_msg[:30]}...)")
            continue

    print("\n‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng model n√†o ch·∫°y ƒë∆∞·ª£c. ƒêang √©p d√πng 'gemini-1.5-flash'...")
    return genai.GenerativeModel("gemini-1.5-flash")

# Kh·ªüi t·∫°o l·∫ßn ƒë·∫ßu
try:
    model = init_gemini_model()
    print("--- AI SYSTEM READY ---")
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o AI Fatal: {e}")

# ====================== BI·∫æN TO√ÄN C·ª§C & H·∫∞NG S·ªê ======================
FLOOD_LEVEL = 90
EMERGENCY_LEVEL = 25 # D∆∞·ªõi m·ª©c n√†y l√† QU√Å KH√î -> G·ªçi AI g·∫•p

REGIONAL_DB = {
    'NORTH': {"H√† N·ªôi":(21.02,105.85), "H·∫£i Ph√≤ng":(20.86,106.68), "L√†o Cai":(22.48,103.97)},
    'CENTRAL': {"ƒê√† N·∫µng":(16.05,108.20), "Hu·∫ø":(16.46,107.59), "Nha Trang":(12.23,109.19)},
    'SOUTH': {"TP.HCM":(10.82,106.62), "C·∫ßn Th∆°":(10.04,105.74), "C√† Mau":(9.17,105.15)}
}
ALL_CITIES = {}
for r in REGIONAL_DB.values(): ALL_CITIES.update(r)

BROKER = "broker.hivemq.com"
PREFIX = "thaocute_smartgarden/"

state = {
    'step': 0, 'region': 'NORTH', 'mode': 'NONE', 'location': "ƒêang d√≤...", 
    'lat': None, 'lon': None, 'soil': 0, 'temp': 25.0, 'humidity': 80, 'rain': 0.0,
    'ai_timing': "...", 'ai_target': "...", 'ai_reason': "...",
    'pump': False, 'warning': "", 'last_ai_call': 0
}

mqtt_client = mqtt.Client(client_id=f"Render_Server_{int(time.time())}")

# ====================== ROUTE WEB (Flask) ======================
@app.route('/', methods=['GET', 'POST'])
def home():
    if 'user' not in session:
        error = None
        if request.method == 'POST':
            u = request.form.get('username'); p = request.form.get('password')
            if u in USERS and USERS[u]['pass'] == p:
                session['user'] = u; session['role'] = USERS[u]['role']
                return redirect('/')
            else: error = "Sai t√™n ho·∫∑c m·∫≠t kh·∫©u!"
        return render_template('login.html', error=error)
    return render_template('dashboard.html', user=session['user'], role=session['role'])

@app.route('/logout')
def logout(): session.clear(); return redirect('/')

@app.route('/api/history')
def get_history():
    date_str = request.args.get('date')
    if db_collection is None: return jsonify([])
    logs = list(db_collection.find({"date": date_str}, {'_id': 0}).sort("created_at", -1))
    return jsonify(logs)

# ====================== LOGIC H·ªÜ TH·ªêNG ======================
def log_event(action, detail):
    if db_collection is None: return
    try:
        now_vn = datetime.utcnow() + timedelta(hours=7)
        record = {"date": now_vn.strftime("%Y-%m-%d"), "time": now_vn.strftime("%H:%M:%S"),
                  "action": action, "detail": detail, "soil": state['soil'], "created_at": now_vn}
        db_collection.insert_one(record)
    except: pass

def broadcast():
    try: mqtt_client.publish(PREFIX + "update", json.dumps(state, ensure_ascii=False))
    except: pass

def update_weather():
    if not state['lat']: return
    try:
        url = f"https://api.openweathermap.org/data/2.5/weather?lat={state['lat']}&lon={state['lon']}&units=metric&appid={OPENWEATHER_KEY}"
        r = requests.get(url, timeout=3).json()
        if r.get('cod') == 200:
            state['temp'] = r['main']['temp']; state['humidity'] = r['main']['humidity']
            state['rain'] = r.get('rain', {}).get('1h', 0.0)
            if "Th·ªß c√¥ng" not in state['location']: state['location'] = r.get('name') + " (VN)"
            if state['mode'] == 'AUTO': threading.Thread(target=ask_gemini, kwargs={'force': False}, daemon=True).start()
    except: pass
    broadcast()

# --- LOGIC AI M·ªöI: 120s TH∆Ø·ªúNG / 30s KH·∫®N C·∫§P ---
def ask_gemini(force=False):
    global model
    
    # 1. X√°c ƒë·ªãnh th·ªùi gian ch·ªù (Cooldown)
    is_emergency = state['soil'] < EMERGENCY_LEVEL
    cooldown_time = 30 if is_emergency else 120  # Kh√¥ qu√° th√¨ 30s, th∆∞·ªùng th√¨ 120s
    
    elapsed = time.time() - state['last_ai_call']
    
    # 2. Ki·ªÉm tra ƒëi·ªÅu ki·ªán ch·∫°y
    if state['mode'] != 'AUTO': return
    
    if not force and elapsed < cooldown_time:
        # Ch·ªâ in log cooldown n·∫øu l√† tr∆∞·ªùng h·ª£p kh·∫©n c·∫•p ƒë·ªÉ debug
        if is_emergency: print(f"‚è≥ ƒê·∫•t kh√¥ ({state['soil']}%) - Ch·ªù {cooldown_time}s (M·ªõi {int(elapsed)}s)")
        return

    print(f"\n--- ü§ñ AI CHECK | Soil={state['soil']}% | Mode={'KH·∫®N C·∫§P' if is_emergency else 'ƒê·ªäNH K·ª≤'} ---")

    # ƒê·∫£m b·∫£o model t·ªìn t·∫°i tr∆∞·ªõc khi g·ªçi
    if model is None:
        model = init_gemini_model()
        if model is None: return

    # 3. Prompt th√¥ng minh
    urgent_note = ""
    if is_emergency:
        urgent_note = "C·∫¢NH B√ÅO: ƒê·∫§T ƒêANG R·∫§T KH√î! H√ÉY ∆ØU TI√äN T∆Ø·ªöI NGAY L·∫¨P T·ª®C!"

    prompt = f"""
    ƒê·ªô ·∫©m ƒë·∫•t: {state['soil']}%. Nhi·ªát ƒë·ªô: {state['temp']}C. M∆∞a 1h: {state['rain']}mm.
    {urgent_note}
    
    B·∫°n l√† h·ªá th·ªëng t∆∞·ªõi c√¢y th√¥ng minh.
    Tr·∫£ l·ªùi DUY NH·∫§T JSON:
    {{
      "action": "T∆Ø·ªöI" ho·∫∑c "KH√îNG",
      "target": ƒê·ªô ·∫©m m·ª•c ti√™u ƒë·ªÉ d·ª´ng b∆°m (b·∫°n ph·∫£i t·ª± d·ª± ƒëo√°n),
      "timing": M√¥ t·∫£ ng·∫Øn g·ªçn bao gi·ªù t∆∞·ªõi(b·∫Øt bu·ªôc ph·∫£i c√≥ th·ªùi gian nh·∫•t ƒë·ªãnh) v√† ƒë·ªô ·∫©m d·ª± ƒëo√°n l√† bao nhi√™u,
      "reason": L√Ω do ng·∫Øn g·ªçn gi·∫£i th√≠ch t·∫°i sao t∆∞·ªõi ƒë·∫øn ƒë·ªô ·∫©m ƒë·∫•y
    }}
    """

    try:
        # --- TH·ª∞C HI·ªÜN G·ªåI AI ---
        # Th√™m c∆° ch·∫ø: N·∫øu l·ªói model th√¨ t·ª± ƒë·ªïi v√† g·ªçi l·∫°i ngay l·∫≠p t·ª©c (Retry logic)
        try:
            response = model.generate_content(prompt)
        except Exception as e:
            if "404" in str(e) or "not found" in str(e):
                print("üîÑ Model hi·ªán t·∫°i b·ªã l·ªói 404. ƒêang ƒë·ªïi model kh√°c v√† TH·ª¨ L·∫†I NGAY...")
                model = init_gemini_model() # T√¨m model m·ªõi
                if model:
                    response = model.generate_content(prompt) # G·ªçi l·∫°i l·∫ßn 2
                else:
                    return # Ch·ªãu thua
            else:
                raise e # N·∫øu l·ªói kh√°c (m·∫°ng r·ªõt...) th√¨ n√©m ra ngo√†i ƒë·ªÉ log

        # 4. X·ª≠ l√Ω k·∫øt qu·∫£ (Parse JSON)
        raw = response.text.strip()
        # print("üìù AI RAW:", raw) # B·∫≠t d√≤ng n√†y n·∫øu mu·ªën debug xem AI tr·∫£ l·ªùi g√¨
        
        text = raw.replace("```json", "").replace("```", "").strip()
        data = json.loads(text)

        action = data.get("action", "KH√îNG")
        target = int(data.get("target", state['soil']))
        timing = data.get("timing", "...")
        reason = data.get("reason", "...")

        state['ai_target'] = target; state['ai_timing'] = timing; state['ai_reason'] = reason
        state['last_ai_call'] = time.time() # C·∫≠p nh·∫≠t th·ªùi gian g·ªçi cu·ªëi

        print(f"üéØ AI ‚Üí {action} | Target={target}% | {timing}")

        if action == "T∆Ø·ªöI": control_pump(True, "AI Decision")
        else: control_pump(False, "AI Decision")

        broadcast()

    except Exception as e:
        print("‚ùå AI ERROR:", e)
        # V·∫´n gi·ªØ d√≤ng n√†y ƒë·ªÉ ph√≤ng h·ªù c√°c l·ªói kh√°c l√†m h·ªèng model
        if "404" in str(e) or "not found" in str(e): 
            model = init_gemini_model()

def control_pump(on, source="System"):
    if on and state['soil'] >= FLOOD_LEVEL:
        on = False; state['warning'] = "NG·∫¨P √öNG! T·ª™ CH·ªêI B∆†M"
    if state['step'] != 2 and on: on = False 
    
    if state['pump'] != on:
        state['pump'] = on
        cmd = "ON" if on else "OFF"
        mqtt_client.publish(PREFIX + "cmd", cmd)
        log_event(f"PUMP_{cmd}", source)
        print(f"üí¶ PUMP {cmd} ({source})")
    
    if not on and state['warning'] == "NG·∫¨P √öNG! T·ª™ CH·ªêI B∆†M": state['warning'] = ""
    broadcast()

def on_message(client, userdata, msg):
    try:
        payload = msg.payload.decode()
        
        # --- 1. NH·∫¨N S·ªê LI·ªÜU T·ª™ ESP (C·∫¢M BI·∫æN) ---
        if msg.topic == PREFIX + "esp/data" and "H:" in payload:
            try:
                # L·∫•y ƒë·ªô ·∫©m hi·ªán t·∫°i
                val = int(payload.split("H:")[1].split()[0])
                state['soil'] = max(0, min(100, val))
                
                # A. AN TO√ÄN TUY·ªÜT ƒê·ªêI: Ng·∫≠p √∫ng (90%) l√† t·∫Øt b∆°m b·∫•t ch·∫•p m·ªçi th·ª©
                if state['soil'] >= FLOOD_LEVEL and state['pump']:
                    control_pump(False, "Safety Cutoff")
                
                # B. LOGIC AUTO (AI)
                elif state['mode'] == 'AUTO':
                    # 1. G·ª≠i d·ªØ li·ªáu cho AI (ƒë·ªÉ n√≥ quy·∫øt ƒë·ªãnh t∆∞·ªõi hay ch·ªù)
                    threading.Thread(target=ask_gemini, kwargs={'force': False}, daemon=True).start()
                    
                    # 2. üî¥ LOGIC NG·∫ÆT B∆†M THEO M·ª§C TI√äU C·ª¶A AI üî¥
                    # Ch·ªâ ki·ªÉm tra khi b∆°m ƒëang B·∫¨T
                    if state['pump']:
                        try:
                            # L·∫•y con s·ªë m·ª•c ti√™u AI ƒë√£ ƒë·∫∑t ra (v√≠ d·ª•: 75)
                            # (Code AI ·ªü tr√™n ƒë√£ l∆∞u s·ªë n√†y v√†o state['ai_target'])
                            target_val = int(state['ai_target'])
                            
                            # So s√°nh: N·∫øu ƒë·ªô ·∫©m hi·ªán t·∫°i >= M·ª•c ti√™u AI
                            # (V√≠ d·ª•: ƒê·∫•t 76% >= M·ª•c ti√™u 75% -> T·∫ÆT)
                            if state['soil'] >= target_val:
                                control_pump(False, f"ƒê·∫°t m·ª•c ti√™u AI ({target_val}%)")
                                print(f"‚úÖ ƒê√£ t∆∞·ªõi xong! ƒê·∫•t ƒë·∫°t {state['soil']}% (M·ª•c ti√™u: {target_val}%)")
                        except:
                            pass # N·∫øu l·ªói ƒë·ªçc s·ªë m·ª•c ti√™u th√¨ b·ªè qua

                broadcast() # G·ª≠i d·ªØ li·ªáu m·ªõi nh·∫•t xu·ªëng Web
            except: pass

        # --- 2. NH·∫¨N S·ª∞ KI·ªÜN T·ª™ WEB (Gi·ªØ nguy√™n kh√¥ng ƒë·ªïi) ---
        elif msg.topic == PREFIX + "events":
            d = json.loads(payload); evt = d.get('event'); data = d.get('data', {})
            
            if evt == 'select_region':
                state['region'] = data['region']; state['step'] = 1; broadcast()
            elif evt == 'enter_mode':
                state['mode'] = data['mode']; state['step'] = 2
                log_event("MODE_CHANGE", f"Chuy·ªÉn ch·∫ø ƒë·ªô {state['mode']}")
                if state['mode'] == 'AUTO': threading.Thread(target=ask_gemini, kwargs={'force': True}, daemon=True).start()
                broadcast()
            elif evt == 'exit_dashboard':
                state['step'] = 0; state['mode'] = 'NONE'; control_pump(False)
            elif evt == 'set_city':
                city = data.get('city')
                if city in ALL_CITIES:
                    state['lat'], state['lon'] = ALL_CITIES[city]
                    state['location'] = f"{city} (Th·ªß c√¥ng)"
                    threading.Thread(target=update_weather, daemon=True).start()
            elif evt == 'set_gps':
                state['lat'] = data['lat']; state['lon'] = data['lon']
                state['location'] = "üìç ƒêang l·∫•y t√™n..."; broadcast()
                threading.Thread(target=update_weather, daemon=True).start()
            elif evt == 'user_control' and state['mode'] == 'MANUAL':
                control_pump(bool(data['pump']), "Ng∆∞·ªùi d√πng b·∫•m")
            broadcast()
    except Exception as e: print(f"‚ùå L·ªói on_message: {e}")

def run_mqtt():
    mqtt_client.on_connect = lambda c,u,f,rc: (c.subscribe([ (PREFIX+"esp/data",0), (PREFIX+"events",0) ]), print("‚úÖ MQTT CONNECTED"))
    mqtt_client.on_message = on_message
    try: mqtt_client.connect(BROKER, 1883, 60); mqtt_client.loop_start()
    except Exception as e: print(f"‚ùå L·ªói MQTT: {e}")

try: run_mqtt(); print("--- Background Thread Started ---")
except: pass

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)

