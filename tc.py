# tc.py ‚Äî SMART GARDEN HYBRID (FLASK + MONGODB + GEMINI SDK 1.0)
import threading, time, json, re, os
import paho.mqtt.client as mqtt
import requests
from datetime import datetime, timedelta
from flask import Flask, render_template, request, jsonify, session, redirect
from pymongo import MongoClient

# üî• SDK AI M·ªöI (GOOGLE GENAI v1.0)
from google import genai
from google.genai import types

# ====================== 1. C·∫§U H√åNH SERVER & DATABASE ======================
app = Flask(__name__)
app.secret_key = 'thao_cute_sieu_cap_vipro'

# T√ÄI KHO·∫¢N
USERS = {
    'admin': {'pass': 'admin123', 'role': 'ADMIN'},
    'khach': {'pass': '1111',     'role': 'VIEWER'}
}

# CONFIG KEYS
GEMINI_KEY = os.getenv("GEMINI_KEY")
OPENWEATHER_KEY = os.getenv("OWM_KEY", "5803b3e6056e6886cfa874414788f232")
MONGO_URI = os.getenv("MONGO_URI")

# MONGODB CONNECT (Thay th·∫ø Firebase)
db_collection = None
try:
    if MONGO_URI:
        mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        mongo_client.server_info() # Check k·∫øt n·ªëi
        db = mongo_client.get_database("smart_garden_db")
        db_collection = db.history
        print("--- MONGODB ATLAS CONNECTED ---")
    else:
        print("‚ö†Ô∏è C·∫£nh b√°o: Ch∆∞a c√≥ MONGO_URI")
except Exception as e:
    print(f"‚ùå L·ªói MongoDB: {e}")
    db_collection = None

# ====================== 2. C·∫§U H√åNH AI (SDK M·ªöI) ======================
ai_client = None
CURRENT_MODEL = "gemini-1.5-flash"

if GEMINI_KEY:
    ai_client = genai.Client(api_key=GEMINI_KEY)

def find_working_model():
    """D√≤ t√¨m model AI c√≤n s·ªëng (Logic gi·ªØ nguy√™n v√¨ r·∫•t t·ªët)"""
    global CURRENT_MODEL
    print("\nüîç ƒêang d√≤ t√¨m model AI...")
    candidates = ["gemini-1.5-flash", "gemini-2.0-flash-exp", "gemini-1.5-pro"]
    
    for name in candidates:
        try:
            ai_client.models.generate_content(
                model=name, contents="Test", 
                config=types.GenerateContentConfig(max_output_tokens=5)
            )
            CURRENT_MODEL = name
            print(f"‚úÖ ƒê√£ ch·ªçn model: {CURRENT_MODEL}")
            return True
        except: continue
    return False

if ai_client: find_working_model()

# ====================== 3. THAM S·ªê H·ªÜ TH·ªêNG (T·ª™ CODE M·∫™U) ======================
CRITICAL_LEVEL = 26  # ƒê·∫•t kh√¥ kh·∫©n c·∫•p
FLOOD_LEVEL    = 90  # Ng·∫≠p √∫ng tuy·ªát ƒë·ªëi

BROKER = "broker.hivemq.com"
PREFIX = "thaocute_smartgarden/"

# DATABASE T·ªàNH TH√ÄNH
REGIONAL_DB = {
    'NORTH': {"H√† N·ªôi":(21.02,105.85), "H·∫£i Ph√≤ng":(20.86,106.68), "L√†o Cai":(22.48,103.97)},
    'CENTRAL': {"ƒê√† N·∫µng":(16.05,108.20), "Hu·∫ø":(16.46,107.59), "Nha Trang":(12.23,109.19)},
    'SOUTH': {"TP.HCM":(10.82,106.62), "C·∫ßn Th∆°":(10.04,105.74), "C√† Mau":(9.17,105.15)}
}
ALL_CITIES = {}
for r in REGIONAL_DB.values(): ALL_CITIES.update(r)

state = {
    'step': 0, 'region': 'NORTH', 'mode': 'NONE', 'location': "ƒêang d√≤...", 
    'lat': None, 'lon': None, 'soil': 0, 'temp': 25.0, 'humidity': 80, 'rain': 0.0,
    'ai_timing': "...", 'ai_target': 75, 'ai_reason': "...", 
    'pump': False, 'warning': "", 'last_ai_call': 0
}

mqtt_client = mqtt.Client(client_id=f"Render_Server_{int(time.time())}")

# ====================== 4. FLASK ROUTES ======================
@app.route('/', methods=['GET', 'POST'])
def home():
    if 'user' not in session:
        if request.method == 'POST':
            u = request.form.get('username'); p = request.form.get('password')
            if u in USERS and USERS[u]['pass'] == p:
                session['user'] = u; session['role'] = USERS[u]['role']
                return redirect('/')
        return render_template('login.html')
    return render_template('dashboard.html', user=session['user'], role=session['role'])

@app.route('/logout')
def logout(): session.clear(); return redirect('/')

@app.route('/api/history')
def get_history():
    date_str = request.args.get('date')
    if not db_collection: return jsonify([])
    try:
        logs = list(db_collection.find({"date": date_str}, {'_id': 0}).sort("created_at", -1))
        return jsonify(logs)
    except: return jsonify([])

# ====================== 5. H√ÄM LOGIC (GH√âP T·ª™ CODE M·∫™U) ======================
def log_event(action, detail):
    """Ghi log v√†o MongoDB"""
    if not db_collection: return
    try:
        now_vn = datetime.utcnow() + timedelta(hours=7)
        record = {
            "date": now_vn.strftime("%Y-%m-%d"), 
            "time": now_vn.strftime("%H:%M:%S"),
            "action": action, "detail": detail, 
            "soil": state['soil'], "created_at": now_vn
        }
        db_collection.insert_one(record)
    except: pass

def broadcast():
    try: mqtt_client.publish(PREFIX + "update", json.dumps(state, ensure_ascii=False))
    except: pass

def update_weather():
    if not state['lat']: return
    try:
        url = f"https://api.openweathermap.org/data/2.5/weather?lat={state['lat']}&lon={state['lon']}&units=metric&appid={OPENWEATHER_KEY}"
        r = requests.get(url, timeout=3).json()
        if r.get('cod') == 200:
            state['temp'] = r['main']['temp']; state['humidity'] = r['main']['humidity']
            state['rain'] = r.get('rain', {}).get('1h', 0.0)
            if "Th·ªß c√¥ng" not in state['location']: state['location'] = r.get('name') + " (VN)"
            
            # Ch·ªâ g·ªçi AI khi c√≥ th·ªùi ti·∫øt m·ªõi V√Ä ƒëang AUTO
            if state['mode'] == 'AUTO':
                threading.Thread(target=ask_gemini, kwargs={'force': False}, daemon=True).start()
    except: pass
    broadcast()

# --- üî• TR√ÅI TIM C·ª¶A H·ªÜ TH·ªêNG: AI LOGIC (ƒê√É GH√âP) ---
def ask_gemini(force=False):
    global CURRENT_MODEL
    
    # 1. Check an to√†n tr∆∞·ªõc
    if state['soil'] >= FLOOD_LEVEL:
        control_pump(False, "Safety Check (Ng·∫≠p)")
        return

    if state['mode'] != 'AUTO' or not ai_client: return

    now = time.time()
    is_emergency = state['soil'] < CRITICAL_LEVEL
    time_diff = now - state['last_ai_call']

    # 2. Logic Cooldown (Gi·ªëng code m·∫´u)
    # - N·∫øu Force (√©p bu·ªôc): Ch·∫°y lu√¥n
    # - N·∫øu Kh·∫©n c·∫•p: Ch·ªù t·ªëi thi·ªÉu 15s (Ch·ªëng spam)
    # - B√¨nh th∆∞·ªùng: Ch·ªù 120s (Ti·∫øt ki·ªám ti·ªÅn/quota)
    if force:
        pass 
    elif is_emergency:
        if time_diff < 15: return 
    else:
        if time_diff < 120: return

    # C·∫≠p nh·∫≠t warning ƒë·ªÉ hi·ªÉn th·ªã Web
    if is_emergency: state['warning'] = "KH·∫®N C·∫§P: ƒê·∫§T QU√Å KH√î!"
    else: state['warning'] = ""

    print(f"\nüì° ƒêang g·ªçi Gemini... (Soil: {state['soil']}%)")

    # 3. Prompt (Gi·ªëng code m·∫´u - K·ªπ s∆∞ n√¥ng nghi·ªáp)
    prompt = f"""
    ƒê√≥ng vai k·ªπ s∆∞ n√¥ng nghi·ªáp.
    D·ªØ li·ªáu: ƒê·∫•t {state['soil']}%, Nhi·ªát {state['temp']}C, M∆∞a {state['rain']}mm.
    Kh·∫©n c·∫•p (<{CRITICAL_LEVEL}%): {is_emergency}.
    
    Y√™u c·∫ßu tr·∫£ v·ªÅ ƒë√∫ng ƒë·ªãnh d·∫°ng JSON: 
    {{ "decision": "ON ho·∫∑c OFF", "timing": "...", "target": s·ªë_nguy√™n, "reason": "..." }}
    
    L∆∞u √Ω:
    - "target": ƒê·ªô ·∫©m m·ª•c ti√™u ƒë·ªÉ d·ª´ng b∆°m (VD: 75).
    - "timing": M√¥ t·∫£ ng·∫Øn g·ªçn bao gi·ªù t∆∞·ªõi.
    - "reason": L√Ω do ng·∫Øn g·ªçn.
    """

    try:
        # G·ªçi SDK M·ªõi
        response = None
        try:
            response = ai_client.models.generate_content(
                model=CURRENT_MODEL, contents=prompt,
                config=types.GenerateContentConfig(response_mime_type="application/json", temperature=0.5)
            )
        except:
            # Retry logic
            if find_working_model():
                response = ai_client.models.generate_content(
                    model=CURRENT_MODEL, contents=prompt,
                    config=types.GenerateContentConfig(response_mime_type="application/json")
                )
            else: return

        # X·ª≠ l√Ω k·∫øt qu·∫£
        if response and response.text:
            # L·ªçc markdown n·∫øu AI l·ª° tay th√™m v√†o
            raw = response.text.replace("```json", "").replace("```", "").strip()
            data = json.loads(raw)

            decision = data.get("decision", "OFF").upper() # ON/OFF
            target   = int(data.get("target", 75))
            timing   = data.get("timing", "...")
            reason   = data.get("reason", "...")

            state['ai_target'] = target
            state['ai_timing'] = timing
            state['ai_reason'] = reason
            state['last_ai_call'] = now

            print(f"üéØ AI ‚Üí {decision} | Target={target}% | {reason}")
            log_event("AI_DECISION", f"AI: {decision} ({reason})")

            control_pump(decision == "ON", "AI Logic")
            broadcast()

    except Exception as e:
        print(f"‚ùå AI Error: {e}")

# ====================== ƒêI·ªÄU KHI·ªÇN B∆†M (GH√âP LOGIC AN TO√ÄN) ======================
def control_pump(on, source="System"):
    # 1. Ch·ªâ cho ph√©p b∆°m ·ªü Step 2 (Mode AUTO/MANUAL)
    if state['step'] != 2 and on: on = False

    # 2. LOGIC CH·ªêNG NG·∫¨P TUY·ªÜT ƒê·ªêI (>= 90%)
    if state['soil'] >= FLOOD_LEVEL and on:
        on = False
        state['warning'] = f"NG·∫¨P √öNG! C·∫§M B∆†M (>{FLOOD_LEVEL}%)"
        print(f"‚ö†Ô∏è [SAFETY] ƒê·∫•t {state['soil']}% -> Block b∆°m!")

    # X√≥a c·∫£nh b√°o n·∫øu ƒë√£ an to√†n
    if not on and CRITICAL_LEVEL <= state['soil'] < FLOOD_LEVEL:
        state['warning'] = ""

    # G·ª≠i l·ªánh MQTT
    if state['pump'] != on:
        state['pump'] = on
        cmd = "ON" if on else "OFF"
        mqtt_client.publish(PREFIX + "cmd", cmd)
        log_event(f"PUMP_{cmd}", source)
        print(f"üí¶ PUMP {cmd} ({source})")

    # D·ª± ph√≤ng: Lu√¥n g·ª≠i OFF n·∫øu ƒë·∫•t ƒëang ng·∫≠p (ƒë·ªÅ ph√≤ng g√≥i tin tr∆∞·ªõc b·ªã m·∫•t)
    elif on == False and state['soil'] >= FLOOD_LEVEL:
        mqtt_client.publish(PREFIX + "cmd", "OFF")

    broadcast()

# ====================== MQTT HANDLE ======================
def on_message(client, userdata, msg):
    try:
        payload = msg.payload.decode()
        
        # --- 1. NH·∫¨N S·ªê LI·ªÜU ---
        if msg.topic == PREFIX + "esp/data" and "H:" in payload:
            try:
                val = int(payload.split("H:")[1].split()[0])
                state['soil'] = max(0, min(100, val))
                
                # A. AN TO√ÄN (Ng·∫≠p l√† c·∫Øt ngay l·∫≠p t·ª©c)
                if state['soil'] >= FLOOD_LEVEL and state['pump']:
                    control_pump(False, "Auto-Cutoff (Sensor)")
                
                # B. LOGIC AUTO
                elif state['mode'] == 'AUTO' and state['step'] == 2:
                    # N·∫øu ƒë·∫•t kh√¥ kh·∫©n c·∫•p -> G·ªçi AI ngay (b·ªè qua cooldown 2 ph√∫t)
                    if state['soil'] < CRITICAL_LEVEL:
                         threading.Thread(target=ask_gemini, kwargs={'force': False}, daemon=True).start()
                    
                    # üî¥ LOGIC T·ª∞ NG·∫ÆT TH√îNG MINH (Target + 3%)
                    # N·∫øu ƒëang b∆°m m√† ƒë·∫•t ƒë√£ ·∫©m h∆°n m·ª•c ti√™u AI ƒë·ªÅ ra 3% -> T·∫Øt
                    if state['pump']:
                        try:
                            target_val = int(state['ai_target'])
                            # B√π 3% cho qu√°n t√≠nh n∆∞·ªõc th·∫•m
                            if state['soil'] >= (target_val + 3):
                                control_pump(False, f"ƒê·∫°t m·ª•c ti√™u {target_val}% (+3%)")
                        except: pass
                
                broadcast() 
            except: pass

        # --- 2. NH·∫¨N S·ª∞ KI·ªÜN T·ª™ WEB ---
        elif msg.topic == PREFIX + "events":
            d = json.loads(payload); evt = d.get('event'); data = d.get('data', {})
            
            if evt == 'select_region':
                state['region'] = data['region']; state['step'] = 1; broadcast()
            elif evt == 'enter_mode':
                state['mode'] = data['mode']; state['step'] = 2
                log_event("MODE_CHANGE", f"Chuy·ªÉn ch·∫ø ƒë·ªô {state['mode']}")
                # V√†o Auto -> G·ªçi AI ngay (Force)
                if state['mode'] == 'AUTO': 
                    threading.Thread(target=ask_gemini, kwargs={'force': True}, daemon=True).start()
                else:
                    control_pump(False, "Init Manual")
                broadcast()
            elif evt == 'exit_dashboard':
                state['step'] = 0; state['mode'] = 'NONE'; control_pump(False); broadcast()
            elif evt == 'set_city':
                city = data.get('city')
                if city in ALL_CITIES:
                    state['lat'], state['lon'] = ALL_CITIES[city]
                    state['location'] = f"{city} (Th·ªß c√¥ng)"
                    threading.Thread(target=update_weather, daemon=True).start()
            elif evt == 'user_control' and state['mode'] == 'MANUAL':
                control_pump(bool(data['pump']), "Ng∆∞·ªùi d√πng b·∫•m")
            
    except Exception as e: print(f"‚ùå L·ªói on_message: {e}")

def run_mqtt():
    mqtt_client.on_connect = lambda c,u,f,rc: (c.subscribe([ (PREFIX+"esp/data",0), (PREFIX+"events",0) ]), print("‚úÖ MQTT CONNECTED"))
    mqtt_client.on_message = on_message
    try: mqtt_client.connect(BROKER, 1883, 60); mqtt_client.loop_start()
    except Exception as e: print(f"‚ùå L·ªói MQTT: {e}")

try: run_mqtt(); print("--- Background Thread Started ---")
except: pass

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port, use_reloader=False)
